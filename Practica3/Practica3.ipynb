{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XRxHiKdGHiT"
   },
   "source": [
    "## Image classification with deep learning methods.\n",
    "\n",
    "-- Description --\n",
    "\n",
    "When you train the network, it is recommended to use the GPU resources of your computer.\n",
    "This will help you to learn the \"know how\" of setting up a working Python environment on your computer.\n",
    "In the case of unavailable Nvidia hardware or problems with your Python environment you can use Google Colab.\n",
    "Please go to the menu, Runtime - Change runtime type, and select **GPU** as the hardware accelerator.\n",
    "Although you used your computer successfuly it is highly recommended to give a try to Google Colab environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Eq1KWmR3HWYV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# These libraries should be sufficient for this Practice.\n",
    "# However, if any other library is needed, please install it by yourself.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# -----------------\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist import OrganAMNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AjMm2LTvVT-f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: medmnist in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (1.26.1)\n",
      "Requirement already satisfied: torch in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (2.2.1)\n",
      "Requirement already satisfied: scikit-image in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (0.22.0)\n",
      "Requirement already satisfied: pandas in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (2.2.1)\n",
      "Requirement already satisfied: torchvision in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (0.17.1)\n",
      "Requirement already satisfied: tqdm in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (1.4.1.post1)\n",
      "Requirement already satisfied: fire in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (0.6.0)\n",
      "Requirement already satisfied: Pillow in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from medmnist) (10.1.0)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from fire->medmnist) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from fire->medmnist) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from pandas->medmnist) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from pandas->medmnist) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from pandas->medmnist) (2024.1)\n",
      "Requirement already satisfied: packaging>=21 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (23.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (3.2.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (2024.2.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (0.3)\n",
      "Requirement already satisfied: imageio>=2.27 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (2.34.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-image->medmnist) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-learn->medmnist) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from scikit-learn->medmnist) (3.4.0)\n",
      "Requirement already satisfied: fsspec in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from torch->medmnist) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from torch->medmnist) (4.10.0)\n",
      "Requirement already satisfied: jinja2 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from torch->medmnist) (3.1.3)\n",
      "Requirement already satisfied: sympy in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from torch->medmnist) (1.12)\n",
      "Requirement already satisfied: filelock in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from torch->medmnist) (3.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->medmnist) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/cmoro/Library/Python/3.9/lib/python/site-packages (from sympy->torch->medmnist) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install and import the MedMNIST package and datasets.\n",
    "\n",
    "%pip install medmnist\n",
    "import medmnist\n",
    "from medmnist import info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1068af070>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preparing the Dataset\n",
    "NUM_EPOCHS = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1234\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4TX-CXBHW4c"
   },
   "source": [
    "## Download the imaging dataset\n",
    "\n",
    "You can browse the imaging datasets on their webpage https://medmnist.com/, and download them as such:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GvH6SWlDQBMf"
   },
   "outputs": [],
   "source": [
    "# from medmnist import OrganAMNIST\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Definir transformaciones que deseas aplicar a tus datos\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((28, 28)),  # Cambiar el tamaño a 64x64\n",
    "#     transforms.ToTensor(),         # Convertir la imagen a un tensor\n",
    "#     transforms.Normalize((0.5,), (0.5,))  # Normalizar las imágenes\n",
    "# ])\n",
    "\n",
    "# # Crear instancia del dataset\n",
    "# dataset = OrganAMNIST(split=\"test\", download=True, transform=transform, size=128)\n",
    "\n",
    "# # Calcular las longitudes de los conjuntos de entrenamiento y prueba\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(0.8 * total_size)\n",
    "# test_size = total_size - train_size\n",
    "\n",
    "# # Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# # Crear DataLoader para manejar los datos de entrenamiento\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# # Crear DataLoader para manejar los datos de prueba\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "# # Ahora puedes iterar sobre los DataLoaders para obtener los lotes de datos\n",
    "# for batch in train_loader:\n",
    "#     # batch contiene un conjunto de imágenes y etiquetas de entrenamiento\n",
    "#     train_images, train_labels = batch\n",
    "#     # Aquí puedes realizar operaciones con los datos del lote de entrenamiento\n",
    "\n",
    "# for batch in test_loader:\n",
    "#     # batch contiene un conjunto de imágenes y etiquetas de prueba\n",
    "#     test_images, test_labels = batch\n",
    "#     # Aquí puedes realizar operaciones con los datos del lote de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'organamnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/cmoro/.medmnist/organamnist.npz\n",
      "Using downloaded and verified file: /Users/cmoro/.medmnist/organamnist.npz\n",
      "Using downloaded and verified file: /Users/cmoro/.medmnist/organamnist.npz\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Opt6Dn_FCD7y"
   },
   "source": [
    "## Visualize the imaging dataset\n",
    "\n",
    "You can find relevant information about the datasets in the info.INFO dictionary.\n",
    "\n",
    "For visualizing the images, you can use the montage method, though we recomend\n",
    "you practice accesing the individual images and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ok-SBMwUXf1"
   },
   "source": [
    "#Generate a dataloader\n",
    "\n",
    "A convinient option for accessing data in torch is with the use of the Dataloader class. These work directly when given a MNIST dataset as input.\n",
    "You can also apply any necesary preprocesing steps directly as you load the data with the Transforms package and the transform MNIST argument.\n",
    "\n",
    "Choose apropiate values for the training hiperparameters (you can experiment with sampling strategies if you want) and implement the adecuate preprocesing steps. Finally, choose an Mnist dataset and create the dataloader for the training, validation and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn-gr3Y1dhc0"
   },
   "source": [
    "#Create a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "X8OH_2iLU6oZ"
   },
   "outputs": [],
   "source": [
    "# # Define a simple CNN model\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, in_channels, num_classes, im_size):\n",
    "#         super(Net, self).__init__()\n",
    "#         # Define the desired deep learning model\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.fc1 = nn.Linear(64 * (im_size // 8) * (im_size // 8), 512)\n",
    "#         self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Convolutional layers with ReLU activation and max pooling\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "\n",
    "#         # Flatten the output for fully connected layers\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Fully connected layers with ReLU activation\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "# # Define the input channels, number of classes, and image size\n",
    "# in_channels = 1  # MNIST images are grayscale, hence 1 channel\n",
    "# num_classes = 10  # Number of classes in MNIST dataset\n",
    "# im_size = 64  # Resized image size\n",
    "\n",
    "# # Create an instance of the model\n",
    "# model = Net(in_channels=in_channels, num_classes=num_classes, im_size=im_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple CNN model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Net(in_channels=n_channels, num_classes=n_classes)\n",
    "    \n",
    "# define loss function and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 270/271 [00:29<00:00,  9.29it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long()\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "        \n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "        \n",
    "print('==> Evaluating ...')\n",
    "test('train')\n",
    "test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtKObx-HVuaG"
   },
   "source": [
    "#Train Model\n",
    "\n",
    "Implement the main traning loop to train the deep learning model.\n",
    "This should include the forward and backward passes. You can find information about how to do this with torch in https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#id14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ENrFXnaOVt0i"
   },
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "#     model.train()\n",
    "#     for inputs, targets in tqdm(train_loader):\n",
    "#         # forward + backward + optimize\n",
    "\n",
    "#         #Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFgraWehfxGu"
   },
   "source": [
    "#Evaluation\n",
    "\n",
    "Finally, implement the evaluation of the object clasification task. You can implement any metric you want, though the most common are accuracy and AUC (one class against all for the multiclass task). You can use torch.no_grad() for speeding up predictions when no gradients are needed.\n",
    "\n",
    "How do you compare with the MedMNIST benchmarks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXT5ny4wVv_G"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# Your code\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
